

## 1、一维优化问题fminbnd
    方法：黄金分割法（迅速缩小极值区间），抛物线法（提高解得精度）
    场景：一维，有边界
min(F(x))
s.t.x1<x<x2
```
[x,fval,exitflag,output]=fminbnd('myfun',x1,x2,options)
```
1. FunValCheck:
on 目标函数为复数或NaN时显示出错信息
off 不显示出错信息

2. exitflag:
1 优化成功
0 迭代到最大(MaxFunEvals,MacIter)退出
-1用户自定义函数退出
-2边界调教不协调(x1>x2)

## 2、无约束优化问题fminsearh
       方法：所用算法是单纯形搜索法，不需要计算梯度
 场景：无约束，多维，有梯度
       模型：min(F(x))
       代码：[x,fval,exitflag,output]=fminbnd('myfun',x0,options)
FunValCheck
       on 目标函数为复数或NaN时显示出错信息
       off 不显示出错信息
OutputFcn 用户自定义的输出函数，它将在每个迭代步调用
PlotFcns   用户自定义的画图函数，它将在每个迭代步调用
exitflags  
            1  求解成功
            0  ...
           -1 ...

## 3、无约束优化问题fminunc
#### 方法：所用算法是搜索法和梯度法结合
#### 模型：min(F(x))

#### 代码
```
[x,fval,exitflag,output,grad,hessian]=fminunc('myfun',x0,options)
```
grad是x点的梯度：
[∂f/x1,∂f/x2,...,∂f/xn]
hessian矩阵：
[∂^2/x1^2,∂^2/x1x2,...,...]

## 4、0-1规划
bintprog???

模型：
min C'X
s.t. A*X<=b
      Aeq*X=beq
      xi=0或1
代码：[x,fval,exitflag,output]=bint('fun',A,b,Aeq,beq,x0,options)

## 5.极小极大fminmax

### 模型：
min(x)max(i){Fi(x)}
s.t.
{
A*X<=b
Aeq*x=beq
c(x)<=0
ceq(x)=0
lb<=x<=ub
}

### 代码:
```
[x,fval,maxfval,exitflag,output,lambda]=fminmax('fun',x0,A,b,Aeq,beq,lb,ub,nonlcon,options)
```
options指定选项：

Derivative:比较用户提供的梯度和有限差分法得出的梯度

Diagnostic:显示诊断信息

DiffMaxChange:有限差分法求梯度时自变量的最大改变量
DiffMinChange:有限差分法求梯度时自变量的最小该变量
GradConstr:约束函数的梯度
GradObj:目标函数的梯度
MaxSQPIter:。。。

## 6.约束优化问题fmincon
[x,fval,exitflag,output,lambda,grad,hessian]=fmincon('fun',x0,A,b,Aeq,beq,lb,ub,nonlcon,options)
lambda: x处的拉格朗日乘子
grad: x处的梯度
hessian: x处的海森矩阵

## 7.非线性最小二乘问题lsqnonlin
min(f(x)^2=f1(x)^2+f2(x)^2+...+fn(x)^2)
[x,resnorm,residual,exitflag,output,lambda,jacobian]=lsqnonlin('fun',x0,lb,ub,options)

## 8.线性规划linprog

[x,fval,exitflag,output,lambda]=linprog('fun',A,b,Aeq,beq,lb,ub,x0,options)

## 9.二次规划quadprog

模型：

$min (1/2*x'* H * x+c'x)$
s.t.
{
Aeq*x=beq
A*x>=b
}
代码：
[x,fval,exitflag,output,lambda] = quadprog(H,f,A,b,Aeq,beq,lb,ub,x0,options)

## 10.目标到达问题
模型：

[x,fval,attainfactor,exitflag,output,lambda] = fgoalattain(fun,x0,goal,weight,A,b,Aeq,beq,lb,ub,nonlcon,options)





## A、初始设定optimset
options=optimset('param1',value1,'param2','value2',...)
options=optimset%生成一个空optimset结构体
options = optimset(options,'Display', 'off');%输入旧的options
### optimset的内容:
1、Display  信息显示
off 不显示迭代信息
iter 显示每次的迭代信息
final 显示最终结果
notify 不收敛时才显示
2、MaxFunEvals 允许函数计算的最大次数，取正整数
3、MaxIter 允许最大迭代次数，取正整数
4、TolFun 函数值精度，取正整数
5、TolX 自变量精度，取正整数
### 输出的内容
1、x  最优的x
2、fval 最优x对应的函数值
3、exitflag   用来评价最优化效果
1、一阶最优性条件满足容许范围
2、X的变化小于容许范围
3、目标函数的变化小于容许范围
4、重要搜索方向小于规定的容许范围并且约束违背小于options.TolCon
5、重要方向导数小于规定的容许范围并且约束违背小于options.TolCon
0、到达最大迭代次数或到达函数评价
-1、算法由输出函数终止
-2、无可行点
4、output 一个含多个参数的结构体
Iteraction  迭代次数
Algorithm  所用算法
FuncCount 函数评价次数

## B、GUI界面
optimtool
