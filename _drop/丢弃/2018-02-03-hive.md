---
layout: post
title: 【丢弃】【Hive】基础知识.
categories: 
tags:
keywords:
description:
order: 161
---

*回收原因：Hive 基本操作很简单，放到这另一篇文章里[【spark, Hive, Hadoop, yarn】汇总](http://www.guofei.site/2018/03/27/spark.html#title7)，更复杂的Hive操作建议使用 spark，因此这篇文章没必要了*
## CLI
命令行界面，是与Hive交互的最常用的方式  
### 1. hive执行脚本

hive -e “sql语句”  
会将查询的结果打印在控制台上。  
`-e` SQL from command line


hive -e “sql语句” > xxx  
会将查询的结果重定向到xxx文件中，会显示OK和抓取的数据条数


hive -S -e “sql语句” > xxx
会将查询的结果重定向到xxx文件中，不会显示OK和抓取的数据条数
`-S` Silent mode  


hive -f sqlfile.sql  
执行文件中的sql（用于sql比较长的时候）  
`-f` SQL from files  
一般把查询文件的后缀名设为.q或.hql


hive -i sqlfile  
执行文件中的sql（用于sql比较长的时候）， 执行完后就不退出，还可继续执行其他sql。在这种模式下若还要去执行其他文件中的sql， 需要在hive模式中使用 source sqlfile 来配合。


### 2. hive与linux交互
例如：当我们使用hive -i sqlfile时，已经进入hive模式中，这时候需要去执行其他的sqlfile，但是不知道sqlfile在什么路径下,这样就显得很尴尬了。  
在hive模式下使用叹号加命令加分号  
`! + linux 命令;`  


### 3. hive与hdfs交互
由于hive已经是运行在hadoop上所以直接可以使用  `dfs + hdfs命令;`

### 4. hive的注释
两个横线开头`-- 注释123`

### 5. 显示字段名
```
hive> set hive.cli.print.header=true;
```


## hive数据类型


- 整型
    - TINYINT — 微整型，只占用1个字节，只能存储0-255的整数。
    - SMALLINT– 小整型，占用2个字节，存储范围–32768 到 32767。
    - INT– 整型，占用4个字节，存储范围-2147483648到2147483647。
    - BIGINT– 长整型，占用8个字节，存储范围-2^63到2^63-1。
- 布尔型
    - BOOLEAN — TRUE/FALSE
- 浮点型
    - FLOAT– 单精度浮点数。
    - DOUBLE– 双精度浮点数。
- 字符串型
    - STRING– 不设定长度。
- TIMESTAMP
    - （最新版本支持）
    - 整数或浮点数：距离1970年1月1日的秒数
    - 字符串"YYYY-MM-DD hh:mm:ss.fffffffff"
    - 不支持时区

### 类型转换
... cast (s AS INT)...;


## 修改数据

Hive没有行级别的insert, update, delete 操作，装载数据唯一的途径就是“大量”数据装载操作。  



这样写，可以防止扫很多分区  

```
FROM staged_employee se
INSERT OVERWRITE TABLE employees PAERTITION (country='US, state='OR')
  SELECT * WHERE se.cnty='US' AND se.st='OR'
INSERT OVERWRITE TABLE employees
  PAERTITION (country='US, state='CA')
  SELECT * WHERE se.cnty='US' AND se.st='CA'
INSERT OVERWRITE TABLE employees
  PAERTITION (country='US, state='IL')
  SELECT * WHERE se.cnty='US' AND se.st='IL';
```

## 其它小知识点
### 压缩
Hive 不强制要求数据格式，Hive利用Hadoop的InputFormat API从不同数据源读取数据，例如文本格式、sequence格式，甚至用户自定义格式。  
压缩可以增加I/O吞吐量，但会增加CPU开销。不过Hadoop的job通常是I/O密集型，而不是CPU密集型，所以压缩可以提高性能。
## 函数
```sql
show functions;
desc function norm; -- 查询函数的详细用法
```

## 参考文献
《Hive编程指南》人民邮电出版社  
mySQL从入门到精通  
https://wenku.baidu.com/view/f7f6e6dcd1f34693daef3e8b.html
《Hive编程指南》Edward ，O‘REILLY  
[Hive 脚本执行](http://blog.csdn.net/zz657114506/article/details/53576711)  
http://flyingdutchman.iteye.com/blog/1868600
