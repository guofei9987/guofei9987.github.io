## 前言
Rosetta石碑有埃及象形文、埃及拼音文、古希腊文，帮助人破译文字
1. 信息冗余是信息安全的保障
2. 语料很重要

为什么十进制呢？
1. 因为手指有10个，
2. 太多的进制导致需要背诵的乘法表平方级增加，如20进制就需要背诵19*19乘法表


中国古文中，常用字笔画比非常用字少，文言文比白话文精炼，都是在压缩信息  
犹太人抄写圣经时，为了防止抄错，会把希伯来字母对应一个数字，然后在每一行计算一个校验码。

## nlp的历史
1956年，香农等级为顶尖科学家研讨一个月，并没有什么突破性成果。因为陷入了一个误区，认为要实现nlp翻译或语音识别，必须先让计算机理解语言。这种思维被称为“鸟飞派”，以为飞机一定要像鸟一样才能飞。  
20世纪60年代，误区是认为首先要做好2件事，分析语句和获取语义。这是因为语法学科非常成熟，有大量论文，完备的体系。基于规则的语法遇到的问题是，一个长句的语法分析树非常复杂；语法规则多达万条，其中还有很多相互矛盾。  
20世纪70年代，基于语义的处理更麻烦，自然语言的多义性、严重依赖上下文，依赖world Knowledge  
1970年至今，统计语言学使nlp重获新生。过去25年统计语言学飞速发展有两个原因：1.统计语言学确实不错，2.老科学家相继退休 3. 市场需求

## n-gram模型
这里介绍了n-gram模型（基于马尔科夫假设），提到一些点：
1. 一般n取1~3，再高计算量显著增加，并且模型效果提升较小，Google的罗塞塔系统n=4，部署在500台机器上
2. n元不能覆盖所有语言现象，因为自然语言上下文关联的跨度可以非常大，甚至跨段落，n再高也无能为力。

### 0概率问题
有些组合在语料库中未出现（或者出现很少），导致无法估计。增加数据量看起来能够解决问题。但是就算把所有网页作为语料，大部分组合的频率仍然是0  
Good-Turing Estimate ：  
假设出现r次的词有$N_r$个，那么对于$r<r_0$的那些，进行这样的调整：  
$d_r=(r+1)N_{r+1}/N_r$  

用文字描述，就是把不常用的组合，概率缩小；很常用的组合，概率不变；未出现的组合，有一个小概率。这样概率之和就为1了。  

### 关于语料库的问题
1. 训练集和应用场景要一致。例如，腾讯搜索早期用人民日报作为语料库，尽管噪声少、错误少，但训练效果不佳。改用网页文本后效果变好
2. 如果有容易检索的噪声，还是预先处理比较好。例如网页中的制表符。

----------------------

以上是第三章（69页之前的内容）  
下面跳到15章（165页）


-----------------

## 文本分类问题
