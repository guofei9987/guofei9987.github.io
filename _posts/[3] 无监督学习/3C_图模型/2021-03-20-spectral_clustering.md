---
layout: post
title: 【Spectral Clustering】谱聚类
categories:
tags: 3-3-图模型
keywords:
description:
order: 370
---

## 原理

谱聚类的特点
- 对数据分布的适应性强
- 聚类效果优秀
- 计算量小
- 实现简单
- 从图论中演化来的算法

### 基础理论1：无向有权图

把每个样本点看成一个有向无权图上的节点，两个点之间的距离看成这个有向无权图上的点之间的权重。

于是从样本点获得一个 Graph，$G(V, E)$  

同时，从图的视角，我们定义几个概念：

- **节点** $(v_1,v_2,...,v_n)$
- **权重**。 $w_{ij}$ 指的是两个点 v_i,v_j之间的 **距离**。这个距离是你根据任务目标去确定的，例如欧氏距离。性质：
  - $w_{ij}=w_{ji}$
  - $w_{ii}=0$
  - **邻接矩阵**，就是 $w_{ij}$ 组成的矩阵
- **度**。一个节点对应的度，定义为其所有权重之和 $d_i=\sum\limits_{j=1}^{n} w_{ij}$
  - **度矩阵**。节点度组成的对角矩阵 $D=diag(d_1,d_2,...,d_n)$
- **邻接矩阵**：$w_{ij}=\exp(-\dfrac{\mid\mid x_i - x_j \mid \mid_2^2 }{2\sigma^2})$。一般使用上面这个定义，有时候也会按照 TOP-K做个截断，对于一个节点，TOP-K以外的权重都置为0，这样得到的邻接矩阵是稀疏矩阵。


### 基础理论2：拉普拉斯矩阵

拉普拉斯矩阵定义为 $L=D-W$

它有很多良好的性质：
1. L 是一个对称矩阵。这是因为D和W都是对称矩阵。
2. L 对应的特征值都是实数。这是因为L是一个实对称矩阵
3. 对于任意向量 $f$，有 $f^T L f=1/2 \sum_{i,j=1}^n w_{ij}(f_i-f_j)^2$
4. 根据性质3，拉普拉斯矩阵是半正定的。

性质3的证明：  
$f^T L f = f^T D f - f^T W f = \sum_{i=1}^n f_i^2 - \sum_{i,j=1}^n w_{ij} f_i f_j$  
$=1/2(\sum_{i=1}^n d_i f_i^2 -2\sum_{i,j=1}^n w_{ij}f_i f_j +\sum_{j=1}^n d_j f_j^2) =1/2 \sum_{i,j=1}^n w_{i,j=1}^n(f_i - f_j)^2$

### 基础理论3：图切分

我们做图上的聚类，实际上就是要把图 G(V,E) 分割成k个子图。  
这k个子图的点的集合记为$A_1,A_2,...A_k$，它们满足 $A_i\cap A_j = \empty (i \neq j)$,并且 $A_1\cup A_2 \cup ... \cup A_k =V$  

并且我们需要定义一个损失函数，使得“组间距离”最大

我们先定义两个点集之间的“距离”，将其定义为顶点的两两距离之和。  
对于$A,B\subset V,A\cap B $，定义$W(A,B)=\sum_{i\in A, j\in B} w_{ij}$  

### 基础理论4：损失函数

共有3种，一一列出：

#### 1. cut

很容易想到，损失函数可以是：  

$cut(A_1,A_2,...,A_k)=1/2 \sum_{i=1}^k(A_i,\bar A_i)$  
其中 $\bar A_i$是 $A_i$ 的补集。  

这么做有个严重的缺点：如果有1个离大家都较远的“游离点”，那么这个游离点会被单独归为一类。

#### 2. 
