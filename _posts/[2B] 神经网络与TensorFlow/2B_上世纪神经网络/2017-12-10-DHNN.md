---
layout: post
title: 离散Hopfield
categories:
tags: 2-2-上世纪神经网络
keywords:
description:
order: 254
---


## 简介
由Hopfield于1982年提出。  


- 离散Hopfield神经网络(DHNN,Discrete Hopfield Neural Network)，神经元的输出是$+1,-1$
- 连续Hopfield神经网络(CHNN,Continues Hopfield Nerual Network)


DHNN是一种单层、二值的反馈网络


## 神经元结构
权值$w_{ij}$并且$w_{ii}=0$  
t时刻，第i个神经元的输入是$s_i(t)$,输出是$x_i(t)$  
因为是全连接，所以$s_i(t)=\sum\limits_{j=1}^N w_{ij}x_j(t)-\theta_i$  
其中，$b_i$是阈值


$x_i(t+1)=f(s_i(t))$  
通常情况下，$$f(s)=\begin{cases}1&   & s>=0\\
-1&   & otherwize\end{cases}$$

## Hopfield的稳定性
因为DHNN的状态数是有限的，因此不会出现无穷大的情况，只有可能出现以下3种情况：
1. 稳定状态：收敛到某个状态，各神经元不再变化
2. 有限环：在几个状态中循环往复
3. 混沌：在无限多个状态之间变化
4. 发散：在DHNN中不可能发散。


## 能量函数

引入能量函数$E=-0.5\sum\limits_{i=1}^N \sum\limits_{j=1}^N w_{ij}x_i x_j +\sum\limits_{i=1}^N \theta_ix_i$  


**能量函数单调不增**  
证明：（用矩阵表示）  
$E(t)=-0.5Y^T w Y +Y^T \theta$  
$\Delta E(t)=E(t+1)-E(t)$  
(代入，拆开)$=-\Delta Y^T(t)wY(t)-0.5\Delta Y^T(t) w\Delta Y(t)+\Delta Y(t) \theta$  
$=-\Delta Y^T(wY(t)-\theta)-0.5\Delta Y^T(t) w\Delta Y(t)$  
### 1. 串行的情况
串行的状态改变是$\Delta Y(t)=[0,...,0,\Delta y_j(t),0,...,0]^T$  
把矩阵形式写开：$\Delta E(t)=-\Delta y_j(t) [\sum\limits_{i=1}^Nw_{ij}y_i-\theta_j]$(这里还用到了$w_{ii}=0$这个恒成立的条件)  


$\Delta y_j(t)$要么为0，要么与$\sum\limits_{i=1}^Nw_{ij}y_i-\theta_j$同号  
命题得证  
### 2. 并行的情况
上面已经证明了$-\Delta Y^T(wY(t)-\theta)\leq 0$  
我们又发现，当$w$为非负定对称矩阵，可以保证$-0.5\Delta Y^T(t) w\Delta Y(t) \leq 0$


也就是说，$w$是非负定对称矩阵时，能量函数也是单调不增的。  


## DHNN的学习
已知K个N维度吸引子$C^k=[c_1^k,c_2^k,...,c_N^k],(k=1,2,...,K)$  


常见的学习法有外积法(Outer Product Method)，投影学习法（Production Learning Method），伪逆法（Pseudo Inverse Method），特征结构法（Eigen Structure Method）  


### 1. 外积法
$w_{ij}=\dfrac{1}{a}\sum\limits_{k=1}^Kc_i^kc_j^k$  
同时，令$w_{ii}=0$  
一般取$a=N$  


写成矩阵形式：  
$w=\dfrac{1}{N}(\sum\limits_{k=1}^K C^k(C^k)^T-KI)$  

### 2. 伪逆法
$w=X(Y^TY)^{-1}Y^T$  


## 记忆容量

定义记忆容量为$\alpha=K/N$  


经过试验近似$K \approx 0.15N$,  
也有$K\leq \dfrac{N}{2\log N}$  

## 应用案例
1. 手写识别，标准手写体的像素数据作为吸引子，训练即可
2. 高校科研能力评价（有监督学习），先求出每个类每个feature的平均，这个平均后的向量是x，手动设定对应的吸引子。开始训练。  


```py
import numpy as np


def func(x):
    if x >= 0:
        return 1
    else:
        return -1


y = np.array([-1, -1, -1])
w = np.array([[0, 1, 2], [1, 0, -3], [2, -3, 0]])
b = np.array([-5, 0, 3])
neural_counts = len(b)

max_loop = 10
# 串行
for loop in range(max_loop):
    for i in range(neural_counts):
        x = 0
        for j in range(neural_counts):
            if j != i:
                x += w[i, j] * y[j]
        x -= b[i]
        y[i] = func(x)
        print(y)
```



## 参考文献
《Matlab神经网络原理与实例精解》陈明，清华大学出版社   
《神经网络43个案例》王小川，北京航空航天大学出版社  
《人工神经网络原理》马锐，机械工业出版社  
