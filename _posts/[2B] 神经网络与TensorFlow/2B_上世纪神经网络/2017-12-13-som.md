---
layout: post
title: SOM
categories:
tags: 2-2-上世纪神经网络
keywords:
description:
order: 257
---

## 介绍

自组织特征映射网络(Self-Organizing Feature Map, SOM, SOFM)，又称为Kohonen网络，由Kohonen于1981年提出。  


是一种无监督、自组织、自学习网络

## 结构
![ann_som.png](/pictures_for_blog/postimg/ann_som.png)

输入层有M个神经元，  
竞争层有$a\times b$个神经元  
输入层与竞争层全连接  


[竞争神经网络](/2017/12/12/competitive.html)采用WTA算法，是“封杀”式的，只有获胜的神经元调整权值，其它神经元都不调整。  
SOM神经网络采用Kohonen算法，不仅获胜的神经元调整权值，周围的神经元也有不同程度的调整，常见的调整方式如下：  


![ann_som1.jpg](/pictures_for_blog/postimg/ann_som1.jpg)


名字分别是a.墨西哥草帽函数，b.大礼帽函数,c. 厨师帽函数。  


## 算法步骤
### 1. 初始化
定义输入层I个神经元，输出层J个神经元。（其中，样本的feature有I个）  
随机初始化权重，并且权重归一化，使得$\hat W_j=\dfrac{W_j}{\mid\mid W_j\mid\mid}$  
建立优胜区域规则$N(t)$，优胜区域随着时间增加而变小  
建立学习率规则$\eta(t)$,使得学习率随着时间增加而减小  


### 2. 接受输入
从训练集中随机选取一个样本做归一化$\hat X =\dfrac{X}{\mid \mid X \mid \mid}$  

### 3. 寻找获胜神经元
竞争层寻找获胜神经元$$j^* =\arg\max\limits_{j\in \{1,2,...n\}}\hat X \hat W_j^T$$  

（详细原理见于[竞争神经网络](/2017/12/12/competitive.html#title3)）

### 4. 调整权值
$W_j(t+1)=W_j+\alpha (\hat X -W_j),\forall j$  
其中，$\alpha=\alpha(\eta,N)$,与学习率$\eta$有关，也与领域半径$N$有关。   


## 参考文献
《神经网络原理及应用》朱大奇，史慧，科学出版社  
《人工神经网络理论及应用》韩立群，机械工业出版社
《Matlab神经网络原理与实例精解》陈明，清华大学出版社   
《神经网络43个案例》王小川，北京航空航天大学出版社  
《人工神经网络原理》马锐，机械工业出版社  
Python实现 http://blog.csdn.net/chenge_j/article/details/72537568  
