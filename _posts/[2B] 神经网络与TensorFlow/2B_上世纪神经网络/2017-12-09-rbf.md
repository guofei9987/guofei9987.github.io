---
layout: post
title: RBF&GRNN
categories:
tags: 2-2-上世纪神经网络
keywords:
description:
order: 253
---

## RBF径向基网络

径向基函数(Radical Basis Function,RBF)是多维空间插值的传统技术，由Powell于1985年提出，1988年由Broomhead和Lowe引入神经网络的设计中。  


结构简单，训练简洁，收敛速度快，能够逼近任意非线性函数。  


### 结构
结构就是典型的前向网络  
总共3层神经元

![ann_rbf.png](/pictures_for_blog/postimg/ann_rbf.png)

#### 1. 输入层
仅用于传递信号
#### 2. 隐藏层
通常的径向基函数是$R(\mid dist\mid)$，其中R单调递增。  


常用的径向基函数：  
$R(x_p-c_i)=\exp(-\dfrac{1}{2\sigma^2}\mid\mid x_p-c_i\mid\mid^2)$  
$x_p$第p个输入样本,  
$c_i$是第i个隐含层节点的参数$(i=1,2,...,I)$  


常用的径向基函数还有另外几种  
$R(r)=(c^2+r^3)^\beta,R(r)=(c^2+r^3)^{-\beta}$  
$R(r)=r^{2k}\ln(r),R(r)=r^{2k+1}$  


#### 3. 输出层
输出层是线性神经元  
$y_j=\sum\limits_{i=1}^k w_{ij}R(x_p-c_i),(j=1,2,...,J)$  

### 学习过程
学习过程需要求解的参数有3类：  
1. 基函数的中心$c_i$  
2. 方差$\sigma$  
3. 隐含层到输出层的权值


有多种学习方法：随机选取中心法、自组织选取法、有监督选取中心法、正交最小二乘法。  


#### 自组织选取法
由两阶段组成：  
1. 自组织学习阶段，无监督学习过程，用于求解$c_i,\sigma$  
2. 有监督学习过程，用于求解$w_{ij}$  


$\sigma=\dfrac{1}{P} \sum\limits_{j}^m\mid\mid d_j -y_j c_i\mid\mid^2$  


##### 步骤1：kmeans确定中心点
就是经典的kmeans  
step1：随机生成I个中心$c_i(i=1,2,...,I)$  
step2：按照距离，把样本分为I类
step3：求出每类的重心，作为新的$c_i$  
step4：转到step2，直到达到迭代停止的条件。  
##### 步骤2：求解方差
$\sigma_i=\dfrac{c_{max}}{\sqrt{2I}}$  
$c_{max}$是中心之间的最大距离  
##### 步骤3：求解权值
定义$$d=\{d_{pj}\},w=\{w_{ij}\}$$，那么  
$w=G^+ d$,   
其中$G^+$表示广义逆

#### 随机选取中心法
与自组织选取法类似，唯一不同时步骤1不用kmeans确定$c_i$，而是用随机数。  

#### 有监督选取法
定义cost function $E=0.5\sum\limits_{k=1}^N e_k^2$,  
其中$e_p=d_p-\sum\limits_{i=1}^IR(x_p-c_i)$  


然后按照梯度下降法求解最优。  

#### 正交最小二乘法
（略）


## 广义回归神经网络GRNN

广义回归神经网络(GRNN,Generalized Regression Neural Network)由Donald F. Specht在1991年提出，它是RBF的一种。  


有很强的非线性映射能力、柔性的网络结构、高度的容错性和鲁棒性  
适用于解决非线性问题。  
GRNN在逼近能力和学习速度上比RBF更有优势。  
在样本较少时，预测效果也很好


### 结构

![ann_grnn.png](/pictures_for_blog/postimg/ann_grnn.png)

#### 1. 输入层
简单传递
#### 2. 模式层
RBF层，神经节点的个数与训练样本的个数相同  
第i个神经元：$p_i=\exp[-\dfrac{(X-X_i)^T(X-X_i)}{2\sigma^2}]$  
其中，
- X是某一次输入的测试样本，
- $X_i$是第i个神经网络节点对应的第i个训练样本
- $\sigma$是超参数，可以人为设定，也可以用GA，PSO等算法获取


#### 3. 求和层
简单求和，权值为1  
$\sum\limits_{i=1}^n p_i$
#### 4. 输出层

## 概率神经网络PNN
和GRNN很像，不多写了，感兴趣可以搜索一下。
## 参考文献
《Matlab神经网络原理与实例精解》陈明，清华大学出版社   
《神经网络43个案例》王小川，北京航空航天大学出版社  
