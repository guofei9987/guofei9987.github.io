---
layout: post
title: 【HanLP】NER流程
categories:
tags: 2-4-NLP
keywords:
description:
order: 341
---



## 介绍

相关项目
- HanLP：[https://github.com/hankcs/HanLP](https://github.com/hankcs/HanLP)
- 示例代码 Java：[https://github.com/hankcs/HanLP/tree/v1.7.5/src/test/java/com/hankcs/book](https://github.com/hankcs/HanLP/tree/v1.7.5/src/test/java/com/hankcs/book)
- 示例代码 Python：[https://github.com/hankcs/pyhanlp/tree/master/tests/book](https://github.com/hankcs/pyhanlp/tree/master/tests/book)
- [模型文件下载](http://nlp.hankcs.com/download.php?file=data), [PKU1988语料下载](http://file.hankcs.com/corpus/pku98.zip)


Java
```xml
<dependency>
    <groupId>com.hankcs</groupId>
    <artifactId>hanlp</artifactId>
    <version>portable-1.7.5</version>
</dependency>
```




## step1:分词模型

[代码（训练和预测）](https://github.com/hankcs/HanLP/blob/422077bddc59a66eaf9170198d5650ffc4686124/src/test/java/com/hankcs/book/ch05/DemoPerceptronCWS.java)


```Java
import com.hankcs.hanlp.HanLP;
import com.hankcs.hanlp.model.perceptron.CWSTrainer;
import com.hankcs.hanlp.model.perceptron.PerceptronLexicalAnalyzer;
import com.hankcs.hanlp.model.perceptron.model.LinearModel;
import com.hankcs.hanlp.seg.Segment;
import com.hankcs.hanlp.seg.common.CWSEvaluator;
import org.junit.Test;

import java.io.IOException;

public class DemoPerceptronCWS {

    static {
      // 此 demo 不涉及词性
        HanLP.Config.ShowTermNature = false;
    }


    public static String TRAIN_PATH = "src/data/test/icwb2-data/training/msr_training.utf8";
    public static String TEST_PATH = "src/data/test/icwb2-data/testing/msr_test.utf8";
    public static String GOLD_PATH = "src/data/test/icwb2-data/gold/msr_test_gold.utf8";
    public static String MODEL_PATH = "src/data/test/msr_cws";
    public static String OUTPUT_PATH = "src/data/test/msr_output.txt";
    public static String TRAIN_WORDS = "src/data/test/icwb2-data/gold/msr_training_words.utf8";

    public static void main(String[] args) throws IOException {

//       要点1： 模型训练
        LinearModel model = new CWSTrainer().train(TRAIN_PATH, MODEL_PATH).getModel(); // 训练模型
        Segment segment = new PerceptronLexicalAnalyzer(model).enableCustomDictionary(false);

//        要点2：模型评估
        System.out.println(CWSEvaluator.evaluate(segment, TEST_PATH, OUTPUT_PATH, GOLD_PATH, TRAIN_WORDS)); // 标准化评测

//       要点3: 模型压缩和保存，入参分别是：模型路径，feature，压缩比例，是否导出为txt
        model.save(MODEL_PATH, model.featureMap.entrySet(), 0.1, true);

//       要点4: 模型使用
        System.out.println(segment.seg("商品和服务"));
    }


    @Test
    public void loadAndEvaluate() throws IOException {
      //        要点5:  加载已保存的模型，并使用
              PerceptronLexicalAnalyzer segment = new PerceptronLexicalAnalyzer(MODEL_PATH);
              segment.enableCustomDictionary(false);
              System.out.println(segment.seg("与川普通电话"));
      //        语料中没有 "川普"，所以分词结果是 [与, 川, 普通, 电话]

      //      要点6： 加入自定义词典
              CustomDictionary.insert("川普", "nrf 1");
              segment.enableCustomDictionaryForcing(true);
              System.out.println(segment.seg("与川普通电话"));
      //       看似结果是好的： [与, 川普, 通电话]
              System.out.println(segment.seg("银川普通人与川普通电话讲四川普通话"));
      //        但是出了新问题：[银, 川普, 通人, 与, 川普, 通电话, 讲, 四, 川普, 通话]

      //      要点7：   Online learning 可以解决此问题，训练次数是需要调参的
              segment.enableCustomDictionary(false);
              // ？？？这里最好改成while循环
              for (int i = 0; i < 3; ++i)
                  segment.learn("人 与 川普 通电话");
              System.out.println(segment.seg("银川普通人与川普通电话讲四川普通话"));
      //       结果完美！ [银川, 普通人, 与, 川普, 通电话, 讲, 四川, 普通话]
    }
}
```


注意几个要点
1. 模型的训练、压缩、保存
2. 模型的加载、使用、评估
3. 模型的调整：自定义词典、在线学习
4. 感知机模型的准召率全面超过HMM，OOV的识别也有极大提高


附加1 :模型压缩和保存
```Java
// 关于模型压缩
LinearModel model = new LinearModel("src/model/cws.bin") // 读入模型
model.save("src/model/compress_cws.bin", 0.5, false)
// 参数分别是：新模型路径，压缩比例，是否同时保存一个 txt 供 debug
// 压缩到 0.5 其实准召下降不大
// 如果再次压缩，模型文件又会减半
```

附加2:segment和LinearModel的互相转化
```Java
// LinearModel 转 segment
PerceptronLexicalAnalyzer segment = new PerceptronLexicalAnalyzer(model);
// PerceptronLexicalAnalyzer segment = (PerceptronLexicalAnalyzer) new PerceptronLexicalAnalyzer(model).enableCustomDictionary(false) ;
// ？？？这好像是个缺陷，用的父类方法 return this

// segment 转 LinearModel
LinearModel newLinearModel=segment.getPerceptronSegmenter().getModel();
```

附加3:增量训练并保存模型
```java
//加载模型
PerceptronLexicalAnalyzer segment = new PerceptronLexicalAnalyzer("src/test/resources/model/compress_cws.bin");
segment.enableCustomDictionary(false);

//增量训练
String words = "社区卫生服务站,社区卫生服务中心,妇幼保健院,妇幼保健站";
for (String word : words.split(",")) {
    String sentence1 = "我去 " + word + " 逛街";
    String sentence = "我去" + word + "逛街";
    System.out.println("training: " + sentence1 + " for word " + word);

    int i = 0;
    while (!segment.seg(sentence).contains(word)) {
        segment.learn(sentence1);
        i++;
        //最多训练5次，不成也就不成了
        if (i > 5) {
            break;
        }
    }
    System.out.println("train result: " + sentence + " -> " + segment.seg(sentence));
}


LinearModel newLinearModel = segment.getPerceptronSegmenter().getModel();
newLinearModel.save("src/test/resources/model/online_compress_cws.bin", newLinearModel.featureMap.entrySet(), 0.0, false);
```


## step2:词性标注

模型训练和保存
```java
public static String PKU199801_TRAIN = "src/data/test/pku98/199801-train.txt"; // 训练集
public static String PKU199801_TEST = "src/data/test/pku98/199801-test.txt"; // 测试集
public static String pos_model = "src/main/resources/model/pku199801_pos.bin"; // posTagger 模型保存位置
public static String NER_MODEL = "src/main/resources/model/pku199801_ner.bin"; // ner 模型保存位置

public static String perceptronModelPath = "src/data/model/perceptronModel_pos.bin";


// 训练并保存模型
@Test
public void tstPosTagger1() throws IOException {
    PerceptronTrainer posTrainer = new POSTrainer();
    //同态的train方法可以指定压缩率
    LinearModel posModel = posTrainer.train(PKU199801_TRAIN, pos_model).getModel();
}



// 读取、评估模型和使用模型
@Test
public void tstPosTagger2() throws IOException {
    LinearModel posModel = new LinearModel(pos_model);
    PerceptronPOSTagger postTagger = new PerceptronPOSTagger(posModel);

    //评估模型
    System.out.printf("感知机 ACC = %.2f%%\n",PosTagUtil.evaluate(postTagger,PKU199801_TEST));

    //使用模型做标注
    System.out.println(Arrays.toString(postTagger.tag("多吃", "苹果", "有益", "健康")));

}


// 用规则调整pos
@Test
public void tstPosTagger3() throws IOException {
    PerceptronLexicalAnalyzer perceptronLexicalAnalyzer = new PerceptronLexicalAnalyzer(
            new PerceptronSegmenter("src/main/resources/model/cws.bin"),
            new PerceptronPOSTagger("src/main/resources/model/pku199801_pos.bin"),
            new PerceptronNERecognizer("src/main/resources/model/ner.bin")
    );

    CustomDictionary.insert("希望小学", "学校 1");
    perceptronLexicalAnalyzer.enableCustomDictionaryForcing(true);

    //仅标注
    System.out.println(Arrays.toString(perceptronLexicalAnalyzer.tag("多吃", "苹果", "有益", "健康")));
    //分词+标注
    System.out.println(perceptronLexicalAnalyzer.analyze("他的希望是希望上希望小学"));
    // 他/r 的/u 希望/n 是/v 希望/v 上/v 希望小学/学校
}

// 使用在线训练来调整模型。原本苹果为 n（名词），希望标注为nr（专有名词）
@Test
public void tstPosTagger4() throws IOException {
    PerceptronLexicalAnalyzer perceptronLexicalAnalyzer = new PerceptronLexicalAnalyzer(
            new PerceptronSegmenter("src/main/resources/model/cws.bin"),
            new PerceptronPOSTagger("src/main/resources/model/pku199801_pos.bin"),
            new PerceptronNERecognizer("src/main/resources/model/ner.bin")
    );

    //训练前
    System.out.println(perceptronLexicalAnalyzer.analyze("他想买苹果手机"));
    //他/r 想/v 买/v 苹果/n 手机/n

    for (int i = 0; i < 100; i++) {
        perceptronLexicalAnalyzer.learn("他/r 的/u 希望/n 是/v 买/v 苹果/nr 手机/n");
    }

    System.out.println(perceptronLexicalAnalyzer.analyze("他想买苹果手机"));
    //他/r 想/v 买/v 苹果/nr 手机/n
}
```


词性标准有个映射关系，还挺坑的 [看](https://github.com/hankcs/HanLP/blob/422077bddc59a66eaf9170198d5650ffc4686124/src/main/java/com/hankcs/hanlp/dependency/nnparser/util/PosTagUtil.java#L29)




## step3:NER


```java
// 训练并保存模型
@Test
public void tstNER1() throws IOException {

    NERTrainer nerTrainer = new NERTrainer();
    LinearModel nerModel = nerTrainer.train("src/data/test/pku98/199801.txt",
            "src/main/resources/model/pku_198801_ner.bin").getModel();
}

// 读取、使用模型
@Test
public void tstNER2() throws IOException {

    LinearModel nerModel = new LinearModel("src/main/resources/model/pku_198801_ner.bin");
    PerceptronNERecognizer perceptronNERecognizer = new PerceptronNERecognizer(nerModel);

    String[] wordArray = {"华北", "电力", "公司"}; // 构造单词序列
    String[] posArray = {"ns", "n", "n"}; // 构造词性序列
    String[] nerTagArray = perceptronNERecognizer.recognize(wordArray, posArray); // 序列标注
    for (int i = 0; i < wordArray.length; i++)
        System.out.printf("%s\t%s\t%s\t\n", wordArray[i], posArray[i], nerTagArray[i]);
    //华北	ns	B-nt
    //电力	n	M-nt
    //公司	n	E-nt
}

//    在线学习
@Test
public void tstNER3() throws IOException {
    PerceptronLexicalAnalyzer perceptronLexicalAnalyzer = new PerceptronLexicalAnalyzer(
            new PerceptronSegmenter("src/main/resources/model/cws.bin"),
            new PerceptronPOSTagger("src/main/resources/model/pku199801_pos.bin"),
            new PerceptronNERecognizer("src/main/resources/model/pku_198801_ner.bin")
    );

    //使用模型
    perceptronLexicalAnalyzer.enableCustomDictionary(false);
    System.out.println(perceptronLexicalAnalyzer.analyze("华北电力公司董事长谭旭光和秘书胡花蕊来到美国纽约现代艺术博物馆参观"));
    //[华北/ns 电力/n 公司/n]/nt 董事长/n 谭旭光/nr 和/c 秘书/n 胡花蕊/nr 来到/v [美国/ns 纽约/ns 现代/t 艺术/n 博物馆/n]/ns 参观/v


    //在线学习
    System.out.println(perceptronLexicalAnalyzer.analyze("与特朗普通电话讨论太空探索技术公司"));

    Sentence sentence = Sentence.create("与/c 特朗普/nr 通/v 电话/n 讨论/v [太空/s 探索/vn 技术/n 公司/n]/nt");
    for (int i = 0; i < 20; i++) {
        if (perceptronLexicalAnalyzer.analyze(sentence.text()).equals(sentence)) break;
        perceptronLexicalAnalyzer.learn(sentence);
    }
    System.out.println(perceptronLexicalAnalyzer.analyze("与特朗普通电话讨论太空探索技术公司"));
}
```







<!-- 一个完整的调研如下：
1。 训练用的语料格式是什么样的
2. 背后的模型如何对应的（例如是单个字作为基本单元，还是一个词；标签如何对应）
3. 模型如何训练
4. 模型如何保存
5. 模型如何加载
6. 模型如何使用
7. 模型如何微调。例如在线学习和用户词典

 -->
