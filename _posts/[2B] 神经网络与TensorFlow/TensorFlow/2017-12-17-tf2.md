---
layout: post
title: 【TensorFlow2】运算符
categories:
tags: 2-3-神经网络与TF
keywords:
description:
order: 282
---

## 运算符
### 标量运算
add,subtract,multiply,div,  
exp,log,  
greater,less,equal  


以下标量运算支持 一维变量、多维矩阵、三种数据结构，自带broadcasting
```py
import tensorflow as tf
sess=tf.Session()
ones=tf.fill(dims=[2,3],value=1.0) # 如果value=1，返回int格式，TF的int格式和float格式不能直接运算
twos=tf.fill(dims=[2,3],value=2.0)


sess.run(tf.add(one2,twos))
sess.run(tf.subtract(ones,twos))
sess.run(tf.multiply(ones,twos))
sess.run(tf.div(ones,twos))

tf.floordiv(4.0,,3.0) # 返回除法的商部分
tf.mod(4.0,3.0) # 返回除法的余数部分

sess.run(tf.exp(twos)) # 返回e^x
sess.run(tf.log(twos)) # 返回 log_e x

# 比较运算符，返回bool类型，自带 broadcasting
sess.run(tf.greater(ones,twos)) # 注意上面写的，自带 broadcasting
sess.run(tf.less(ones,3))
sess.run(tf.equal(ones,1))

# 数学函数
abs, sqrt, square
ceil, floor，round
exp, log, power
maximum, minmum
neg # 负数
cos,sin
inv # 倒数
rsqrt # 平方根的倒数
sign # 符号，-1,0,1
```

### 张量拼接、裁剪
concat, slice, split, shape, random_shuffle
```py
import tensorflow as tf
sess=tf.Session()
ones=tf.fill(dims=[2,3],value=1.0)
twos=tf.fill(dims=[2,3],value=2.0)

sess.run(tf.concat(values=[ones,twos],axis=0)) # 0是纵向拼接，1是横向拼接

const=tf.constant(np.arange(50).reshape(5,-1))
sess.run(tf.slice(const,begin=[1,1],size=[2,5]))
# 取出一个分块矩阵，
# 分块矩阵的左上角坐标是 begin （从0开始数起）
# 分块矩阵的各边长度是 size （size从1开始数起，-1表示取到底）
sess.run(const[2:4,:-1]) # a more pythonic way ， 与list类似，含头不含尾

sess.run(tf.random_shuffle(const)) # 打乱顺序，只是按列打乱


split0,split1,split2=tf.split(value=const,num_or_size_splits=[3,4,3],axis=1)
# 功能：分割矩阵。示例代码是把矩阵分割成3列，4列，3列
# 或者这样写：
split0,split1,split2=sess.run(tf.split(value=const,num_or_size_splits=[3,4,3],axis=1))

sess.run(tf.random_crop(const,[2,2]))
# 返回指定大小的随机一块

const.shape # 返回类似 TensorShape([Dimension(5), Dimension(10)]) 的对象
```


### 矩阵运算
MatMul, MatrixInvers,MatrixDeterminant
```py
import tensorflow as tf
sess=tf.Session()
const1=tf.truncated_normal(shape=(5,5),stddev=1.0)
const2=tf.truncated_normal(shape=(5,4),stddev=0.5)


sess.run(tf.matmul(const1,const2)) # 矩阵积
sess.run(tf.matrix_inverse(const1)) # 矩阵逆
tf.transpose(const1) # 矩阵的转置
sess.run(tf.matrix_determinant(const1)) # 方阵对应的行列式
tf.cholesky(const1) # cholesky 分解，前提是矩阵对称正定，作者可以LU分解
eig_value,eig_vector=tf.self_adjoint_eig(a) # 特征值和特征向量


tf.cross([1,1,1],[2,2,2]) # 向量的差积
```
### 带状态运算
assign, assign_add, assign_sub
```py
import tensorflow as tf
sess=tf.Session()
variable1=tf.Variable(initial_value=np.arange(25).reshape(5,-1),dtype=tf.float32)
ones=tf.fill(dims=(5,5),value=1.0)

new_variable1=tf.add(variable1,ones)
updater=tf.assign(variable1,new_variable1)
sess.run(tf.global_variables_initializer())

for i in range(5):
    sess.run(updater)
    print(sess.run(variable1))


# assign_add, assign_sub
import tensorflow as tf
sess=tf.Session()
variable1=tf.Variable(initial_value=np.arange(25).reshape(5,-1),dtype=tf.float32)
ones=tf.fill(dims=(5,5),value=1.0)


updater=tf.assign_add(variable1,ones)
sess.run(tf.global_variables_initializer())

for i in range(5):
    sess.run(updater)
    print(sess.run(variable1))
```


### 矩阵求和运算
reduce_sum, reduce_mean,reduce_prod, reduce_max, reduce_min,  
reduce_all, reduce_any
```py
import tensorflow as tf
import numpy as np
sess=tf.Session()
const1=tf.constant(np.arange(12).reshape(3,-1),dtype=tf.float32)

tf.reduce_sum(const1,axis=None,keep_dims=False) # 对行列求和，返回 66
# axis=None （default） 对所有元素求和
# axis=0 对行求和
# axis=1 对列求和
# keepdims=True 保持维度。例如，axis=1时，默认会把列求和后的结果压成1维，keepdims=True 保证结果的维度和 input_tensor 保持一致

# 一下同类函数，参数都类似于上面
reduce_mean,reduce_prod, reduce_max, reduce_min,

tf.reduce_all(input_tensor=const1>5,axis=1,keepdims=True)
tf.reduce_any(input_tensor=const1>5,axis=1,keepdims=True)
```

## 其它
```py
# class 格式转化为 OneHot
tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)
# indices: 输入
# depth：class 个数
# on_value, off_value # 默认是1,0
```

```
tf.reshape(tensor,(m,n))
```

## 参考文献
[tf API 研读2：math](https://blog.csdn.net/u014365862/article/details/77847410?locationNum=9&fps=1)  
《Matlab神经网络原理与实例精解》陈明，清华大学出版社   
《神经网络43个案例》王小川，北京航空航天大学出版社  
《人工神经网络原理》马锐，机械工业出版社  
白话深度学习与TensorFlow，高扬，机械工业出版社  
《TensorFlow实战Google深度学习框架》，郑泽宇，中国工信出版集团  
