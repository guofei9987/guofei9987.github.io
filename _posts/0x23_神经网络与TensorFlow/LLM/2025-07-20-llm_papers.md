---
layout: post
title: 【读论文】大模型相关
categories:
tags: 0x23_深度学习
keywords:
description:
order: 250
---


## 一些论文


### CoT

*Chain-of-Thought Prompting Elicits Reasoning in Large Language Models* （2022）


![CoT](/a/nn/papers/cot.svg)

这篇论文提出了 **CoT（Chain-of-Thought）**，探索如何通过引导大型语言模型（LLMs）生成中间推理步骤，显著提升其复杂推理能力：


**一、研究背景与动机**
1. LLMs的局限：尽管 LLM 规模扩大能提升性能和数据效率，但仅靠“提高模型大小”无法让模型在**算术推理、常识推理、符号推理**等复杂任务中表现优异（例如传统“标准提示”下，模型难以解决多步数学应用题）。
2. 现有方法的不足：  
   - 「基于原理的微调」：需人工构建大量高质量推理步骤（比简单输入输出对成本高），且任务特异性强；  
   - 「传统少样本提示」：仅提供“输入-输出”示例，在推理任务中效果差，且性能随模型规模增长提升有限。
3. 研究核心思路：  
   结合上述两种方法的优势——用「少样本提示」的便捷性，搭配「中间推理步骤（思维链）」的有效性，提出**CoT**：在提示中提供少量「输入-思维链-输出」三元组示例，引导模型生成连贯的中间推理步骤，最终得到正确答案。


**二、思维链提示的定义与核心特性**
1. 定义：（不摘抄了）
    - 标准提示是 “问题→答案” 对
    - 思维链提示：“问题→推理步骤→答案”
2. **4个关键特性**：  
   - 「分步拆解」：将多步问题分解为中间步骤，为复杂任务分配更多计算资源；  
   - 「可解释性」：推理步骤可追溯，便于定位模型推理错误（如计算错误、语义理解偏差）；  
   - 「任务通用性」：适用于算术、常识、符号等各类人类可通过语言推理的任务；  
   - 「便捷性」：无需微调模型，仅需在少样本提示中加入思维链示例，即可激活大模型的推理能力。


**三、实验设计与核心结果**

研究在**算术推理、常识推理、符号推理**三大类任务中验证思维链提示的效果，涉及5类主流LLMs（GPT-3、LaMDA、PaLM、UL2、Codex）

算术推理（核心任务：数学应用题）
- Benchmarks：GSM8K（多步数学题）、SVAMP、ASDiv、AQuA、MAWPS；  
- 关键结果：  
    - 「规模涌现性」：思维链提示的优势仅在**百亿级参数模型**中体现（如PaLM 540B），小模型（<10B参数）会生成流畅但逻辑错误的推理步骤，性能反而低于标准提示；  
    - 「性能跃升」：PaLM 540B用思维链提示在GSM8K上以 57%正确率，刷新提示的（18%），超过经微调+验证器的GPT-3（55%），刷新SOTA；  
    - 「任务难度适配」：问题越复杂，思维链提示的提升越显著（如GSM8K提升翻倍）；但是，简单的问题（MAWPS中最简单的部分）没有提升，甚至负提升。  
    - 「ablation验证」：仅输出公式（无自然语言推理）、仅增加token长度（如输出“…”）的效果接近基线，证明**自然语言推理步骤是性能提升的核心**。
- 案例分析。分析了50个正确结果，48个 CoT 与结论连贯。分析了50个错误结果，一半 CoT 有重大错误。
- 鲁棒性。CoT 风格变动的影响较小

常识推理
- Benchmarks：CSQA（常识问答）、StrategyQA（多步策略推理）、Date Understanding（日期计算）、Sports Understanding（体育场景合理性判断）、SayCan（机器人动作规划）；  
- 关键结果：  思维链提示在所有任务中均优于标准提示，且模型规模越大提升越明显：  
  - PaLM 540B在StrategyQA上达75.6%正确率，超过此前SOTA（69.4%）；  
  - Sports Understanding任务中，模型正确率（95.4%）超过人类体育爱好者（84%）；  
  - 仅CSQA任务提升有限（因任务对推理步骤依赖较低）。


符号推理（任务：抽象符号操作与长度泛化）
- 实验设置：  任务：① 末尾字母拼接（如“Lady Gaga”→“ya”）；② 硬币翻转状态跟踪（如“初始正面→翻转1次→是否正面”）；  
- 关键测试：设置域内测试集（示例的推理步数与训练 / 少样本示例步数相同）、域外测试集（评测示例的推理步数多于少样本示例中的步数）
- 关键结果：  
  - 「域内完美表现」：PaLM 540B用思维链提示在2步任务上正确率接近100%；  
  - 「域外泛化能力」：标准提示在长步骤任务中完全失效，而思维链提示使PaLM 540B在4步任务上仍保持75%+正确率，证明其能帮助模型**泛化到未见过的推理长度**。


**四、局限性与未来方向**
1. 局限性：  
   - 模拟人类推理过程，但无法证明模型真的具备“推理能力”  
   - 标注成本：少样本场景下标注成本低，但若用于微调，大规模思维链标注仍昂贵
   - 「推理错误风险」：模型可能生成逻辑错误的思维链却巧合得到正确答案，或推理步骤完全错误；  
   - 成本高：仅大模型有效

2. 未来方向：  
   - 探索更小模型的推理能力激活方法；  
   - 用合成数据自动生成思维链，降低标注成本；  
   - 提升思维链的逻辑性与正确性（如加入推理验证器）。

