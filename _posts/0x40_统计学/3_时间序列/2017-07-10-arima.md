---
layout: post
title: 【ARIMA】理论与实现
categories:
tags: 0x43_时间序列
keywords:
description:
order: 443
---

*本文信息密度极高，请慢速阅读*  

平稳性检验通过后，Ljung-Box q检验拒绝白噪声假设，就可以使用本文的建模方法了。

ARMA模型的前提是数据平稳。  

## AR(p)模型
(Auto Regression Model)  
### 定义
$AR(p):y_t=\phi_0+\phi_1 y_{t-1}+\phi_2 y_{t-2}+...+\phi_p y_{t-p}+\varepsilon_t$  
$\phi_p \neq 0$  
$E\varepsilon_t=0,Var(\varepsilon_t)=\sigma_\varepsilon^2,E(\varepsilon_t\varepsilon_s)=0,s\neq t$，也就是白噪声过程  
$Ey_s\varepsilon_t=0,\forall s<t$，也就是回归的自变量与残差无关。  

#### 中心化AR模型
当$\phi_0=0$,称为中心化AR(p)模型  
附加条件序列平稳后，$Ex_t=\dfrac{\phi_0}{1-\phi_1-...-\phi_p}$  
可以把AR(p)中心化：$y_t=x_t-Ex_t$  

### 算子
#### 延迟算子
记$B$为延迟算子，定义为$x_{t-p}=Bx_t$

中心化AR(p)又可以记为：  
$\Phi(B)x_t=\varepsilon_t$  
其中，$\Phi(B)=1-\phi_1B-\phi_2B^2-...-\phi_pB^p$  

#### 格林函数
AR(p)模型为例，如果平稳，那么可以写成  
$x_t=\dfrac{\varepsilon_t}{\Phi(B)}=\sum\limits_{i=1}^p\dfrac{k_i}{1-\lambda_i B}\varepsilon_t=\sum\limits_{i=1}^p\sum\limits_{j=0}^\infty k_i(\lambda_i B)^j\varepsilon_t=\sum\limits_{j=0}^\infty\sum\limits_{i=1}^p k_i \lambda_i^j\varepsilon_{t-j}$ 定义为 $\sum\limits_{j=0}^\infty G_j \varepsilon_{t-j}$

记$G(B)=\sum\limits_{j=0}^\infty G_j B^j$,AR(p)模型就可以记为  
$x_t=G(B)\varepsilon_t$

### 平稳
AR(p)模型本身不要求序列平稳，但往往平稳过程才能用于AR(p)的分析中。  
因此，使用AR之前，要判别序列是否平稳。  
序列平稳性方面的知识见于[另一篇文章](http://www.guofei.site/2017/12/04/timeseries.html)  
AR(p)平稳性判别有两种方法：
1. 特征根判别
2. 平稳域判别


#### 1. 特征根判别
**TH** $AR(p)$平稳的充要条件是它的p个特征根都在单位圆内。  

也就是，$\Phi(B)=0$对应的特征方程，$\Phi(\lambda)=0$的根（叫做 **特征根** ）在单位圆外。  


（特征方程是这个：$\lambda^p-\phi_1 \lambda^{p-1}-\phi_2\lambda^{p-2}-...-\phi_p=0$  
它的根叫做特征根)  


#### 2. 平稳域判别
根据解的取值范围，判断系数$\phi$约束集合$$\{\phi_1,\phi_2,...\phi_p \mid$$特征根都在单位圆内}  


### AR(p)的性质
均值(如果平稳):$Ex_t=\dfrac{\phi_0}{1-\phi_1-...-\phi_p}$  
如果是中心化$AR(p)$，并且要求序列平稳的话，  
$r_k=\phi_1r_{k-1}+\phi_2 r_{k-2}+...+\phi_p r_{k-p}$  
(证明：$E(x_tx_{t-k})=\phi_1E(x_{t-1}x_{t-k})+...+\phi_pE(x_{t-p}x_{t-k}))+E(\varepsilon_t x_{t-k})$)  
（附加平稳性条件后，可以推导出AR(p)的ACF拖尾性）  


在AR(p)模型中，p阶PACF的值，实际上就是AR(p)第p项回归系数值。（根据PACF的定义推导）  


以AR(1),AR(2)为例：  
ACF:  
$AR(1):\rho_k=\phi_1^k$  
$$AR(2):\rho_k=\left \{ \begin{array}{cc}
1&k=0 \\
\dfrac{\phi_1}{1-\phi_2}&k=1\\
\phi_1\rho_{k-1}+\phi_2\rho_{k-2}&k\geq 2
\end{array}\right.$$  
PACF:  
$$AR(1):\rho_k=\left \{ \begin{array}{cc}
\phi_1&k=0 \\
0&k\geq 1
\end{array}\right.$$  
$$AR(2):\rho_k=\left \{ \begin{array}{cc}
\dfrac{\phi_1}{1-\phi_2}&k=1 \\
\phi_2&k=2\\
0&k> 2
\end{array}\right.$$  




## MA(q)模型
(Moving Average Model)  
$MA(q):y_t=c+\varepsilon_t-\theta_1 \varepsilon_{t-1}-\theta_2 \varepsilon_{t-2}-...-\theta_q \varepsilon_{t-q}$  
其中，  
$\theta_q\neq 0$  
$E(\varepsilon_t)=0,D\varepsilon_t=\sigma_\varepsilon^2,E(\varepsilon_t\varepsilon_s)=0,s\neq t$（白噪声）  
当$c=0$,称为 **中心化MA(q)** 模型  


也可以写成：  
$y_t=\Theta(B)\varepsilon_t$  
$\Theta(B)=1-\theta_1B-\theta_2B^2-...-\Theta_qB^q$  


### MA的性质
常数均值$Ex_t=u$  
常数方差$Dx_t=(1+\theta_1^2+...+\theta_q^2)\sigma_\varepsilon^2$  
自协方差函数q阶截尾（证明提要：$Ex_sx_t$,滞后多于q不相关，少于q有限个相关）  


MA还有一个性质，同一组自相关和偏自相关系数，可以对应两个MA模型，定义其中一个叫做 **可逆的MA模型**。  
可逆MA模型的形式与AR类似，所以也可以使用单位根判别其是否是AR模型  
可逆MA模型可以转换成$AR(\infty)$  









## ARMA(p,q)模型
(Auto Regressioin Moving Average Model)  
$ARMA(p,q):y_t=c+\phi_1 y_{t-1}+\phi_2 y_{t-2}+...+\phi_p y_{t-p}+\varepsilon_t-\theta_1 \varepsilon_{t-1}-\theta_2 \varepsilon_{t-2}-...-\theta_q \varepsilon_{t-q}$
其中，  
$\phi_p\neq0,\theta_q\neq 0$  
$E(\varepsilon_t)=0,D\varepsilon_t=\sigma_\varepsilon^2,E(\varepsilon_t\varepsilon_s)=0,s\neq t$（白噪声）  
$Ex_s\varepsilon_t=0,\forall s<t$，也就是回归的自变量与残差无关。  


当$c=0$,称为中心化$ARMA(p,q)$模型  


**平稳性**：AR部分的自回归系数多项式$\Phi(B)=0$的根都在单位圆外  
**可逆性**：MA部分的移动平均系数多项式$\Theta(B)=0$的根都在单位圆外  


## p,d,q的确定

### d的识别
ARMA模型要求数据平稳，当数据不平稳时，需要差分。如果d阶差分后，序列平稳，叫做`d阶单整序列`  
如果差分很多次，还是不平稳。或者差分后已经失去研究意义了，那么就放弃ARIMA模型。  

### p,q的识别

||AR(p)|MA(q)|ARMA(p,q)|
|--|--|--|--|
|ACF|拖尾|q期后截尾|拖尾|
|PACF|p期后截尾|拖尾|拖尾|


识别的困难：  
由于样本的随机性，样本ACF,PACF不会呈现完美的理论截尾情况，而是在零值附近震荡，因此需要用统计学手段进行假设检验  


Barlett
:    $\hat\rho_k\sim N(0,1/n),n\to \infty$  


Quenouille
:    $\hat\phi_{kk}\sim N(0,1/n),n\to \infty$  


求出各自的95%置信区间:  
$Pr(-2/\sqrt n<\hat\rho_k<2/\sqrt n)>0.95$  
$Pr(-2/\sqrt n<\hat\phi_{kk}<2/\sqrt n)>0.95$  
以这个方法定阶：  
**d阶之前明显在落在置信区间外，d阶之后几乎95%落在置信区间内，并且d阶前后衰减非常突然，那么判断截尾阶数为d**  


## 参数估计
确定模型以及p,q后，有p+q+2个参数需要估计：  
$\phi_1,...,\phi_p,\theta_1,...,\theta_q,u,\sigma_\varepsilon^2$  
1. 距估计
2. 极大似然估计
3. 最小二乘法


### 1. 矩估计
用样本的自相关系数估计总体的自相关系数，用样本的均值估计总体的均值，用样本的方差估计总体的方差。  
用系数表示以上统计量，便可以列方程计算系数。  
（思路简单，但公式比较复杂，就不放公式了）  


优点：
1. 思路简单
2. 不需要假设总体分布
3. 低阶场合下，计算量小


缺点：  
1. 信息浪费严重：只用到p+q个样本的自相关系数。
2. （所以）估计精度差  


在极大似然估计和最小二乘法中，需要迭代运算，那么迭代的最初值往往用矩估计的结果。  


### 2. 极大似然估计
先假定正态分布，然后求似然函数（式子复杂，略过）


优点：  
1. 充分运用每一个观察值的信息，精度高
2. 有优良的统计性质


缺点：
1. 需要假定总体分布（正态分布）


### 3. 最小二乘估计

$\min\sum(x_t-\phi_1x_{t-1}-...-\phi_px_{t-p}+\theta\varepsilon_{t-1}+...+\theta_q\varepsilon_{t-q})^2$  


优点：  
1. 充分运用每一个观察值的信息，精度高
2. 有优良的统计性质


缺点：
1. 需要假定总体分布（正态分布）



## ACF和PACF

### ACF

自相关系数ACF的定义：  
$r_k=\rho(y_t,y_{t-k})=\dfrac{cov(y_t,y_{t-k})}{\sqrt{var(y_t)var(y_{t-k})}}$  

计算公式是：  
$r_k=\dfrac{\sum\limits_{t=1}^{n-k}(Y_t-\bar Y)(Y_{t+k}-\bar Y)}{\sum\limits_{t=1}^n(Y_t-\bar Y)^2}$

ACF也是一个随机变量。当序列$\{ Y_t \}$是完全随机序列时，$ACF\sim N(0,1/\sqrt n )$

### PACF  

偏自相关系数PACF的定义：$Y_t$在给定$Y_{t-1},Y_{t-2},...Y_{t-k+1}$的条件下，$Y_t$与$Y_{t-k}$之间的条件相关。  
$\rho_{x_t,x_{t-k}\mid x_{t-1},...,x_{t-k+1}}=\dfrac{E(y_t-E y_t)E(y_{t-k}-E y_{t-k})}{E(y_{t-k}-E y_{t-k})^2}$  





计算方法：  
$$\left\{ \begin{array}{ccc}
\rho_1=\phi_{k1}\rho_0+\phi_{k2}\rho_1+...+\phi_{kk}\rho_{k-1}\\
\rho_2=\phi_{k1}\rho_1+\phi_{k2}\rho_0+...+\phi_{kk}\rho_{k-2}\\
.........................................\\
\rho_k=\phi_{k1}\rho_{k-1}+\phi_{k2}\rho_{k-2}+...+\phi_{kk}\rho_0\\
\end{array}\right.$$  
其中，$\phi$就是偏自相关系数，$\rho$是已经计算得到的自相关系数  


（另一本书上看到的计算方式）  
$$\phi_{kk} = \left \{ \begin{array}{ccc}
r_1,&&k=1\\
\dfrac{r_k-\sum\limits_{j=1}^{k-1} \phi_{k-1,j}\cdot r_{k-j}}{1-\sum\limits_{j=1}^{k-1}\phi_{k-1,j} \cdot r_j}&&k=2,3,...
\end{array}\right.$$  

其中，  
$\phi_{k-j}=\phi_{k-1,j}-\phi_{kk}\phi_{k-1,k-j}$  


## 模型检验
1. 模型显著性检验：用来检验模型对信息的提取是否充分
2. 参数显著性检验：用来检验模型结构是否最简


### 1. 模型显著性检验
检验对象：残差序列  
判断原则：一个好的拟合模型，应该能够提取几乎所有信息，那么残差序列应该是白噪声序列。如果残差不是白噪声序列，说明还有信息没有提取完全  


(见于[【统计时序2】平稳性](http://www.guofei.site/2017/12/04/timeseries.html#title15))中的白噪声检验部分  
H0$\rho_1=\rho_2=...=\rho_m=0$  
然后用LB统计量服从卡方分布，从而进行检验  
p>0.05,不拒绝原假设，认为牟星显著。  


### 2. 参数显著性检验

检验参数是否显著非0，删除不显著的参数，使模型结构最简


H0:$\beta_j=0$  
构建统计量$T=\sqrt{n-m}\dfrac{\hat\beta_j-\beta_j}{a_{jj}Q(\beta)}\sim t(n-m)$  
p<0.05,否定原假设，说明系数显著。  


## 模型优化
问题提出：当一个拟合模型通过了检验，说明在一定的置信水平下，该模型能有效地拟合观察值序列的波动，但这种有效模型并不是唯一的。  


优化的目的：选择相对最优模型  


一个例子：  
某个时间序列ACF 2阶截尾，适合MA(2)模型；同时PACF 1阶截尾，适合AR(1)模型。  
首先拟合MA(2),AR(1)两个模型，发现方程显著，参数也显著。  
同一个序列可以构造两个拟合模型，两个模型都显著有效，那么到底该选择哪个模型用于统计推断呢？   


### AIC准则
最小信息量准则（An Information Criterion）
指导思想：  
1. 似然函数值越大越好
2. 未知参数的个数越少越好


AIC统计量$AIC=n\ln(\hat\sigma_\varepsilon^2)+2k$  
其中，  
第一部分是似然函数的相反数，  
k是未知参数的个数  


### BIC准则
AIC的缺陷：在样本容量趋于无穷大时，由AIC准则选择的模型不收敛于真实模型，它通常比真实模型所含的未知参数个数要多  
$AIC=n\ln(\hat\sigma_\varepsilon^2)+\ln(n)k$  

## 时间序列的预测

1. 线性预测函数:就是把各期数字代入式子，求出结果
2. 方差最小原则  
可以计算一下值的表达式：  
$E(x_{t+l}\mid x_t,x_{t-1},...)$  
$Var(x_{t+l}\mid x_t,x_{t-1},...)$  
进而找出95%置信区间。  


对于AR模型，期数越多，95%置信区间越大。  
对于MA模型，期数越多，方差越大，若干期后，均值和方差都固定到最大。  
对于ARMA模型，


### 修正预测
定义：  
所谓的修正预测就是研究如何利用新的信息去获得精度更高的预测值   
方法：  
在新的信息量比较大时——把新信息加入到旧的信息中，重新拟合模型   
在新的信息量很小时——不重新拟合模型，只是将新的信息加入以修正预测值，提高预测精度  




## Python实现
<iframe src="https://www.guofei.site/StatisticsBlog/arma.html" width="100%" height="3600em" marginwidth="10%"></iframe>
